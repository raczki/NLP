# Desafíos de Procesamiento de Lenguaje Natural (NLP) - Especialización en Inteligencia Artificial (FIUBA)

**Autor:** Karen Raczkowski

En el transcurso de la materia, se llevaron a cabo una serie de trabajos prácticos que abarcaron diversas áreas del Procesamiento de Lenguaje Natural (NLP). En este repositorio se encuentran los temas vinculados a la materia, así como las soluciones a los ejercicios propuestos en diferentes etapas del curso.

## Desafío 1: Vectorización

En este primer desafío, nos adentramos en el mundo de la vectorización de texto. Aprendimos a representar palabras y textos en formatos numéricos, lo que nos permitió:

- **Obtener un vocabulario del corpus.**
- **Realizar One-Hot Encoding:** Convertir textos en matrices binarias.
- **Generar matrices de frecuencia de palabras.**
- **Crear matrices TF-IDF:** Comprender la relevancia de las palabras en documentos.
- **Comparar documentos:** Utilizando la similitud coseno.

## Desafío 2: Bot con NLTK

El segundo desafío nos sumergió en la construcción de un bot de obtención de información utilizando NLTK. A través de este desafío, logramos crear un bot capaz de extraer información utilizando un corpus de Wikipedia sobre Argentina.

## Desafío 3: Embeddings

Utilizando Gensim y el libro "Game of Thrones", conseguimos:

- **Obtención del corpus:** Recopilamos y procesamos el texto completo del libro "A Game of Thrones" (primera entrega de la serie "A Song of Ice and Fire") para su posterior análisis.
- **Creación de vectores de palabras:** Utilizamos Gensim para generar vectores de palabras que representan términos y conceptos presentes en el libro.
- **Análisis de términos:** Exploramos términos específicos presentes en el libro y examinamos sus representaciones vectoriales.
- **Explicación de similitudes:** Comparamos vectores de palabras para identificar similitudes semánticas entre términos y conceptos en el espacio de embeddings.

![Visualizacion](Ejercicio%203/image.png)

## Desafío 4: RNN - Predicción de la próxima palabra

El último desafío nos introdujo en las Redes Neuronales Recurrentes (RNN) y su aplicación en la predicción de la próxima palabra en X. En este desafío, logramos construir un modelo de RNN capaz de generar predicciones de palabras en contexto.

